# Gesture Recognition Using Meta Quest 2 built-in hand tracking

This project is created in name of my Graduation Work at Digital Arts and Entertainement.

With gesture recognition on the horizon, this paper tries to find an intuitive method of detecting complex gestures using the Meta Quest 2 built-in hand tracking.  After defining and classifying gestures it discusses how the challenges of hand tracking bleed over to gesture recognition. Potential methods for gesture recognition such as one-shot learning and $P recognition are discussed while the paper tries to distinguish a suitable technique that can add to the existing components of the Interaction SDK. 

A functional method called Camera-Based Stroke Gesture detection, based on the $P recognizer, is proposed as a component to detect coarse dynamic gestures. In conjunction with the existing Interaction SDK components, the system is capable of detecting complex gestures. The used system architecture is discussed followed by an overview of the development progress. 


 # Technical details
 ## Unity version
 2021.3.15f1 (LTS)
 
 ## Packages used
 
 ### Essential
 - [Oculus Integration](https://assetstore.unity.com/packages/tools/integration/oculus-integration-82022)
 - [PDollar Point-Cloud Gesture Recognizer](https://assetstore.unity.com/packages/tools/input-management/pdollar-point-cloud-gesture-recognizer-21660)
 
 ### Artistic
 - [Unity Particle Pack](https://assetstore.unity.com/packages/essentials/tutorial-projects/unity-particle-pack-127325)
 - [Unity Particle Pack 5.x](https://assetstore.unity.com/packages/essentials/asset-packs/unity-particle-pack-5-x-73777)
 - [3D Game Kit](https://assetstore.unity.com/packages/templates/tutorials/3d-game-kit-115747)
